{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict,cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.models import save_model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"last_expr_or_assign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'font.family'    : 'serif',  # 衬线字体族\n",
    "          'font.serif'     : 'Times New Roman',\n",
    "          'legend.fontsize': 20,\n",
    "          'figure.dpi'     : 100,\n",
    "          'savefig.dpi'    : 600,\n",
    "        #   'figure.figsize' : (15, 5),\n",
    "          'axes.labelsize' : 20,\n",
    "          'axes.titlesize' : 20,\n",
    "          'xtick.labelsize': 20,\n",
    "          'ytick.labelsize': 20,\n",
    "          }\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"FE_trainData_AB_AB.xlsx\", index_col=0, header=0)\n",
    "\n",
    "x = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "x_train_dim = x.shape[1]\n",
    "\n",
    "x = MinMaxScaler().fit_transform(x)\n",
    "y = np.array(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "\t\"\"\"自定义损失函数RMSE\"\"\"\n",
    "\trmse = K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\treturn rmse\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "\t\"\"\"自定义评估函数R2\"\"\"\n",
    "\tRSS = K.sum(K.square(y_true - y_pred))\n",
    "\tTSS = K.sum(K.square(y_true-K.mean(y_true)))\n",
    "\tr_square = 1 - RSS/TSS\n",
    "\treturn r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layers = [\n",
    "Dense(512,input_shape=(x_train_dim,), kernel_regularizer=regularizers.l1(0.001), activation='relu', name=\"Input_Layer\"),\n",
    "# Dense(512, activation='relu', name=\"Hidden_Layer_5\"),\n",
    "# Dropout(0.3),\n",
    "Dense(256, activation='relu', name=\"Hidden_Layer_9\"),\n",
    "# Dropout(0.2),\n",
    "Dense(128, activation='relu', name=\"Hidden_Layer_12\"),\n",
    "# Dropout(0.1),\n",
    "Dense(64, activation='relu', name=\"Hidden_Layer_14\"),\n",
    "Dense(32, activation='relu', name=\"Hidden_Layer_15\"),\n",
    "Dense(1, activation='linear', name=\"Output_Layer\"),\n",
    "]\n",
    "\n",
    "# Create and compile model\n",
    "model = Sequential(feature_layers)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mae', optimizer=opt, metrics=[r_square, rmse, 'mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define 10-fold cross validation test harness\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# 保存交叉验证的评分\n",
    "cross_validation = pd.DataFrame(index=list(range(kfold.n_splits)), \n",
    "                                columns=['LOSS', 'R2', 'RMSE', 'MAE', 'MSE'])\n",
    "\n",
    "# 保存交叉验证模型在独立测试集上的评分\n",
    "holdout_test = pd.DataFrame(index=list(range(kfold.n_splits)), \n",
    "                            columns=['train_R2','train_RMSE','train_MAE','test_R2','test_RMSE','test_MAE'])\n",
    "\n",
    "for fold_index, (cv_train_index, cv_test_index) in enumerate(kfold.split(x_train, y_train)):\n",
    "    checkpointer = ModelCheckpoint(filepath='{}_best_model.h5'.format(fold_index),\n",
    "                                monitor='val_loss',\n",
    "                                mode='auto',\n",
    "                                verbose=0,\n",
    "                                save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                factor=0.2,\n",
    "                                patience=5,\n",
    "                                min_lr=0.001)\n",
    "    callback_lists=[checkpointer]\n",
    "    # Fit the model\n",
    "    history = model.fit(x_train[cv_train_index], y_train[cv_train_index], \n",
    "                        validation_data=(x_train[cv_test_index], y_train[cv_test_index]),\n",
    "                        callbacks=callback_lists,\n",
    "                        epochs=300, batch_size=16, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(x_train[cv_test_index], y_train[cv_test_index], batch_size=32, verbose=0)\n",
    "    cross_validation.loc[fold_index] = scores \n",
    "\n",
    "    \n",
    "    # 模型预测\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    \n",
    "    # 保存每一次交叉验证的预测结果\n",
    "    y_train_pred = y_train_pred.reshape(-1)\n",
    "    y_test_pred = y_test_pred.reshape(-1)\n",
    "    # train_data = pd.DataFrame({\"y_train\":y_train,\"y_train_pred\":y_train_pred}, index=x_train_index)\n",
    "    # test_data = pd.DataFrame({\"y_test\":y_test,\"y_test_pred\":y_test_pred}, index=x_test_index)\n",
    "    train_data = pd.DataFrame({\"y_train\":y_train,\"y_train_pred\":y_train_pred})\n",
    "    test_data = pd.DataFrame({\"y_test\":y_test,\"y_test_pred\":y_test_pred})\n",
    "    train_data.to_excel(\"{}_train_set.xlsx\".format(fold_index))\n",
    "    test_data.to_excel(\"{}_test_set.xlsx\".format(fold_index))\n",
    "    \n",
    "    # 预测得分\n",
    "    train_R2 = r2_score(y_train, y_train_pred)\n",
    "    train_RMSE = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    train_MAE = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "    test_R2 = r2_score(y_test, y_test_pred)\n",
    "    test_RMSE = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_MAE = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    # 保存每一次交叉验证模型在独立测试集上的预测得分\n",
    "    holdout_test.loc[fold_index] = [train_R2,train_RMSE,train_MAE,test_R2,test_RMSE,test_MAE]\n",
    "\n",
    "    fig=plt.figure(figsize=(15,5))\n",
    "    fig.patch.set_alpha(1)  # 设置绘图背景不透明\n",
    "    spec=fig.add_gridspec(nrows=1,ncols=2,width_ratios=[2,3])    \n",
    "    # 绘制model预测结果散点图\n",
    "    ax1=fig.add_subplot(spec[0,0])\n",
    "    # fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 5), constrained_layout=True)\n",
    "    ax1.scatter(y_train, y_train_pred, c='y', s=50, alpha=0.5, label='train set')\n",
    "    ax1.scatter(y_test, y_test_pred, c='r', s=50, alpha=0.5, label='test set')\n",
    "    ax1.plot([-4, 0.2],[-4, 0.2], c='k', linewidth=1)\n",
    "    ax1.axis([-4, 0.2,-4, 0.2])\n",
    "    ax1.set_xlabel('DFT')\n",
    "    ax1.set_ylabel('ANN')\n",
    "    ax1.legend(loc='upper left', framealpha=0, markerscale=1.5)\n",
    "    # 在图中绘制表格\n",
    "    train_R2   = \"{:.2f}\".format(train_R2)\n",
    "    train_RMSE = \"{:.4f}\".format(train_RMSE)\n",
    "    train_MAE  = \"{:.4f}\".format(train_MAE)\n",
    "    test_R2    = \"{:.2f}\".format(test_R2)\n",
    "    test_RMSE  = \"{:.4f}\".format(test_RMSE)\n",
    "    test_MAE   = \"{:.4f}\".format(test_MAE)\n",
    "    row_labels = [r'$R^2$','RMSE','MAE']\n",
    "    col_labels = ['Train', 'Test']\n",
    "    table_vals = [[train_R2, test_R2],[train_RMSE, test_RMSE] ,[train_MAE, test_MAE]]\n",
    "    table = plt.table(cellText=table_vals, \n",
    "                    rowLabels=row_labels, \n",
    "                    colLabels=col_labels,\n",
    "                    colWidths=[0.2]*3,\n",
    "                    cellLoc='center', \n",
    "                    rowLoc='center', \n",
    "                    colLoc='center',\n",
    "                    loc='lower right',\n",
    "                    )\n",
    "    table.set_fontsize(16) # 表格字体大小\n",
    "    table.scale(1, 1.8)    # 表格缩放\n",
    "    # plt.savefig('{}_result.png'.format(fold_index))\n",
    "    \n",
    "    # 绘制模型metrics趋势线\n",
    "    ax2=fig.add_subplot(spec[0, 1])\n",
    "    # fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 6), constrained_layout=True)\n",
    "    ax2.plot(history.history['rmse'], 'b-', label='train_rmse')\n",
    "    ax2.plot(history.history['val_rmse'], 'r-', label='test_rmse')\n",
    "    ax2.plot(history.history['mae'], 'g-', label='train_mae')\n",
    "    ax2.plot(history.history['val_mae'], 'y-', label='test_mae')\n",
    "    ax2.set_ylim([0, 1])\n",
    "    ax2.legend(loc='center', framealpha=0, ncol=1)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('RMSE(eV)')\n",
    "    # 绘制R2\n",
    "    ax3 = ax2.twinx()\n",
    "    ax3.plot(history.history['r_square'], 'b-', label=r'train_$R^2$')\n",
    "    ax3.plot(history.history['val_r_square'], 'r-', label=r'test_$R^2$')\n",
    "    ax3.set_ylim([0, 1])\n",
    "    ax3.legend(loc='center right', framealpha=0, ncol=1)\n",
    "    ax3.set_ylabel(r'$R^2$')\n",
    "    plt.savefig('{}_metrics.png'.format(fold_index))\n",
    "\n",
    "cross_validation.loc['mean'] = np.mean(cross_validation)      # 添加一行平均值\n",
    "cross_validation.loc['std'] = np.std(cross_validation)        # 添加一行标准差\n",
    "cross_validation = np.around(cross_validation.astype('float64'), decimals=4) # 保留4位小数，返回结果为DataFrame\n",
    "\n",
    "holdout_test.loc['mean'] = np.mean(holdout_test)      # 添加一行平均值\n",
    "holdout_test.loc['std'] = np.std(holdout_test)        # 添加一行标准差\n",
    "holdout_test = np.around(holdout_test.astype('float64'), decimals=4)    # 保留4位小数，返回结果为DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation.to_excel('cross_validation.xlsx')\n",
    "cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_test.to_excel('holdout_test.xlsx')\n",
    "holdout_test"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c33a13e87ff2ca5ca34b26e4f5be8fc0369394a1c92123d92e1f37cab1bd527"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('keras': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
